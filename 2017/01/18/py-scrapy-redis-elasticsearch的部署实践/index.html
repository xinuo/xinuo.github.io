<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python,scrapy,redis,elasticsearch," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="py-scrapy-redis-elasticsearch的部署实践
由于公司项目需要，需要用到python-scrapy-redis-elasticsearch这种分布式爬虫的技术栈，所以现在将整个安装，部署步骤一一记录下来。方便自己或者有相同需要的人。

1. 前言：1.1 作用其实，对于了解过爬虫项目的人来说，python-scrapy已经比较成熟的爬虫框架。它能简单快捷地部署爬虫框架，并通">
<meta property="og:type" content="article">
<meta property="og:title" content="py-scrapy-redis-elasticsearch的部署实践">
<meta property="og:url" content="http://xinuo.github.io/2017/01/18/py-scrapy-redis-elasticsearch的部署实践/index.html">
<meta property="og:site_name" content="Xinuo">
<meta property="og:description" content="py-scrapy-redis-elasticsearch的部署实践
由于公司项目需要，需要用到python-scrapy-redis-elasticsearch这种分布式爬虫的技术栈，所以现在将整个安装，部署步骤一一记录下来。方便自己或者有相同需要的人。

1. 前言：1.1 作用其实，对于了解过爬虫项目的人来说，python-scrapy已经比较成熟的爬虫框架。它能简单快捷地部署爬虫框架，并通">
<meta property="og:image" content="http://od5y2z5kt.bkt.clouddn.com/%E6%95%99%E7%A8%8BQQ%E6%88%AA%E5%9B%BE20170117235931.png">
<meta property="og:image" content="http://od5y2z5kt.bkt.clouddn.com/%E6%95%99%E7%A8%8BQQ%E6%88%AA%E5%9B%BE20170118004610.png">
<meta property="og:updated_time" content="2017-01-19T02:19:57.301Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="py-scrapy-redis-elasticsearch的部署实践">
<meta name="twitter:description" content="py-scrapy-redis-elasticsearch的部署实践
由于公司项目需要，需要用到python-scrapy-redis-elasticsearch这种分布式爬虫的技术栈，所以现在将整个安装，部署步骤一一记录下来。方便自己或者有相同需要的人。

1. 前言：1.1 作用其实，对于了解过爬虫项目的人来说，python-scrapy已经比较成熟的爬虫框架。它能简单快捷地部署爬虫框架，并通">
<meta name="twitter:image" content="http://od5y2z5kt.bkt.clouddn.com/%E6%95%99%E7%A8%8BQQ%E6%88%AA%E5%9B%BE20170117235931.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://xinuo.github.io/2017/01/18/py-scrapy-redis-elasticsearch的部署实践/"/>





  <title> py-scrapy-redis-elasticsearch的部署实践 | Xinuo </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?30b02f423920c48b3f3bced8617ccbaf";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Xinuo</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-python">
          <a href="/categories/python/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heart"></i> <br />
            
            python
          </a>
        </li>
      
        
        <li class="menu-item menu-item-jiagou">
          <a href="/categories/%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%B7%AF/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-paper-plane"></i> <br />
            
            架构之路
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://xinuo.github.io/2017/01/18/py-scrapy-redis-elasticsearch的部署实践/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Cry Rain">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Xinuo">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Xinuo" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                py-scrapy-redis-elasticsearch的部署实践
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-18T17:06:00+08:00">
                2017-01-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="py-scrapy-redis-elasticsearch的部署实践"><a href="#py-scrapy-redis-elasticsearch的部署实践" class="headerlink" title="py-scrapy-redis-elasticsearch的部署实践"></a>py-scrapy-redis-elasticsearch的部署实践</h1><blockquote>
<p>由于公司项目需要，需要用到python-scrapy-redis-elasticsearch这种<strong>分布式爬虫</strong>的技术栈，所以现在将整个安装，部署步骤一一记录下来。方便自己或者有相同需要的人。</p>
</blockquote>
<h2 id="1-前言："><a href="#1-前言：" class="headerlink" title="1. 前言："></a>1. 前言：</h2><h3 id="1-1-作用"><a href="#1-1-作用" class="headerlink" title="1.1 作用"></a>1.1 作用</h3><p>其实，对于了解过爬虫项目的人来说，python-scrapy已经比较成熟的爬虫框架。它能简单快捷地部署爬虫框架，并通过配置简单的参数，使用Xpath、CSS selector来捕获网页的元素，从而达到抓取，爬取的目的。<br>而加入了redis这种noSQL数据库后，可以使scrapy实现分布式的爬虫方案。<br>最后加入Elasticsearch(es)则是使爬取的数据实时记录在ES中，继而前端页面调用、分析等后续任务，是属于实时查询的过程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">graph LR</div><div class="line">Python--&gt;Scrapy</div><div class="line">Redis--&gt;Scrapy</div><div class="line">Scrapy--&gt;Elasticsearch</div><div class="line">Elasticsearch--&gt;下游的操作</div></pre></td></tr></table></figure>
<h3 id="1-2-系统环境"><a href="#1-2-系统环境" class="headerlink" title="1.2 系统环境"></a>1.2 系统环境</h3><blockquote>
<p>OS:window<br>Python:2.7<br>scrapy:<br>IDE: Pycharm<br>Py-Redis:<br>Elasticsearch:5.1.x</p>
</blockquote>
<h2 id="2-下载安装步骤"><a href="#2-下载安装步骤" class="headerlink" title="2. 下载安装步骤"></a>2. 下载安装步骤</h2><h3 id="2-1-Python"><a href="#2-1-Python" class="headerlink" title="2.1 Python"></a>2.1 Python</h3><p>python现在有两个版本。2.x以及3.x，总体来说，3.x是以后发展的趋势，但是2.x却是更成熟的版本。对于我自己来说。还是采用2.x。</p>
<h4 id="2-1-1-Python下载"><a href="#2-1-1-Python下载" class="headerlink" title="2.1.1 Python下载"></a>2.1.1 Python下载</h4><p>python下载的网址是<a href="https://www.python.org/downloads/" target="_blank" rel="external">https://www.python.org/downloads/</a>，那里有最新的版本。而我在这里演示的是：<a href="https://www.python.org/ftp/python/2.7.13/python-2.7.13.msi" target="_blank" rel="external">2.7.13</a></p>
<h4 id="2-1-2-Python安装"><a href="#2-1-2-Python安装" class="headerlink" title="2.1.2 Python安装"></a>2.1.2 Python安装</h4><p>安装过程就跟普通的程序安装差不多。只需要采用默认的配置，一直下一步就行了。安装完毕后，把python程序以及python的一些脚本添加到系统变量里。<br><img src="http://od5y2z5kt.bkt.clouddn.com/%E6%95%99%E7%A8%8BQQ%E6%88%AA%E5%9B%BE20170117235931.png" alt="image"><br>然后打开命令行，输入python,看到以下内容便说明python安装成功。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C:\Users\J&gt;python</div><div class="line">Python 2.7.9 (default, Dec 10 2014, 12:28:03) [MSC v.1500 64 bit (AMD64)] on win32</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure></p>
<h3 id="2-2-pycharm"><a href="#2-2-pycharm" class="headerlink" title="2.2 pycharm"></a>2.2 pycharm</h3><p>pycharm是Jetbrain公司开发的一款用于python开发的软件。这个公司旗下还有很多语言的IDE，可以说在开发领域上十分碉堡的公司。</p>
<h4 id="2-2-1-pycharm下载"><a href="#2-2-1-pycharm下载" class="headerlink" title="2.2.1 pycharm下载"></a>2.2.1 pycharm下载</h4><p>pycharm主页：<a href="http://www.jetbrains.com/pycharm/" target="_blank" rel="external">http://www.jetbrains.com/pycharm/</a><br>pycharm下载页面在这<a href="http://www.jetbrains.com/pycharm/download/#section=windows" target="_blank" rel="external">http://www.jetbrains.com/pycharm/download/#section=windows</a>，有两个版本，一个是Community(社区版)是免费的，是一个轻量的python IDE。还有一个专业版，则是需要收费。所以建议使用Community版本。<br><a href="https://download.jetbrains.com/python/pycharm-community-2016.3.2.exe" target="_blank" rel="external">https://download.jetbrains.com/python/pycharm-community-2016.3.2.exe</a></p>
<h4 id="2-2-2-pycharm安装"><a href="#2-2-2-pycharm安装" class="headerlink" title="2.2.2 pycharm安装"></a>2.2.2 pycharm安装</h4><p>安装步骤其实还是跟普通的软件安装是一样的。只需要一直默认下一步就可以了。</p>
<h4 id="2-2-3-新建一个python项目"><a href="#2-2-3-新建一个python项目" class="headerlink" title="2.2.3 新建一个python项目"></a>2.2.3 新建一个python项目</h4><p>打开pycharm后可以看到类似下图<br><img src="http://od5y2z5kt.bkt.clouddn.com/%E6%95%99%E7%A8%8BQQ%E6%88%AA%E5%9B%BE20170118004610.png" alt="image"><br>此时你就可以新建、打开或者使用版本控制(CVS)程序来实现你的第一个python程序了。<br>不妨创建个helloworld吧。</p>
<h3 id="2-3-scrapy"><a href="#2-3-scrapy" class="headerlink" title="2.3 scrapy"></a>2.3 scrapy</h3><p>scrapy的官网是：<a href="https://scrapy.org/" target="_blank" rel="external">https://scrapy.org/</a>打开后有提示教你怎么安装。</p>
<h4 id="2-3-0-pip的配置"><a href="#2-3-0-pip的配置" class="headerlink" title="2.3.0 pip的配置"></a>2.3.0 pip的配置</h4><p>由于国内连接pypi的源不稳定,所以一般采用国内的镜像.</p>
<blockquote>
<p>如果想配置成默认的源，方法如下：<br>需要创建或修改配置文件（一般都是创建）<br>linux的文件在~/.pip/pip.conf<br>windows在%HOMEPATH%\pip\pip.ini  </p>
</blockquote>
<p>修改内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[global]</div><div class="line">index-url = http://pypi.douban.com/simple</div><div class="line">trusted-host = pypi.douban.com</div></pre></td></tr></table></figure></p>
<h4 id="2-3-1-scrapy下载安装"><a href="#2-3-1-scrapy下载安装" class="headerlink" title="2.3.1 scrapy下载安装"></a>2.3.1 scrapy下载安装</h4><p>由于python有pip的管理安装包，所以我们可以根据<a href="https://doc.scrapy.org/en/1.3/intro/install.html" target="_blank" rel="external">官网</a>的提示安装，由于我们在2.1.2里添加了系统变量，所以打开CMD，输入以下命令进行下载安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#安装incremental</div><div class="line">pip install incremental</div></pre></td></tr></table></figure>
<p>下载并安装 <a href="https://pypi.python.org/packages/01/f3/f325c5d8908af822e9027861f107c04bfedd9cc02fc9aa3a4eb352b32917/lxml-3.1.2.win32-py2.7.exe#md5=c089bbd8452480912001c3700ff47f8f" target="_blank" rel="external">lxml-3.1.2.win32-py2.7.exe</a></p>
<p>下载安装 VCForPython27.msi<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#安装scrapy</div><div class="line">pip install scrapy</div></pre></td></tr></table></figure></p>
<p>这样就可以顺利安装上scrapy</p>
<h4 id="2-3-2-Scrapy-tutorial"><a href="#2-3-2-Scrapy-tutorial" class="headerlink" title="2.3.2 Scrapy tutorial"></a>2.3.2 Scrapy tutorial</h4><p>在安装完scrapy的时候,我们可以新建一个scrapy项目.而scrapy自带就有一个创建模板.<br>在你创建的工作目录下输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">scrapy startproject &lt;项目名&gt; :</div><div class="line">scrapy startproject tutorial</div><div class="line">#然后可以看到以下的内容:</div><div class="line">C:\Users\lzx\Desktop\python&gt;scrapy startproject tutorial</div><div class="line">New Scrapy project &apos;tutorial&apos;, using template directory &apos;c:\\python27\\lib\\site</div><div class="line">-packages\\scrapy\\templates\\project&apos;, created in:</div><div class="line">    C:\Users\lzx\Desktop\python\tutorial</div><div class="line"></div><div class="line">You can start your first spider with:</div><div class="line">    cd tutorial</div><div class="line">    scrapy genspider example example.com</div><div class="line">#然后输入</div><div class="line">cd tutorial</div><div class="line">scrapy genspider example example.com</div></pre></td></tr></table></figure></p>
<p>便可生成简单的scrapy框架的爬虫.</p>
<hr>
<p><strong>注意,以下内容摘录自 <a href="http://www.cnblogs.com/txw1958/archive/2012/07/16/scrapy-tutorial.html" target="_blank" rel="external">http://www.cnblogs.com/txw1958/archive/2012/07/16/scrapy-tutorial.html</a></strong></p>
<h5 id="2-3-2-1-目录结构"><a href="#2-3-2-1-目录结构" class="headerlink" title="2.3.2.1 目录结构"></a>2.3.2.1 目录结构</h5><p>这个命令会在当前目录下创建一个新目录tutorial，它的结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">T:\tutorial&gt;tree /f</div><div class="line">Folder PATH listing</div><div class="line">Volume serial number is 0006EFCF C86A:7C52</div><div class="line">T:.</div><div class="line">│  scrapy.cfg</div><div class="line">│</div><div class="line">└─tutorial</div><div class="line">    │  items.py</div><div class="line">    │  pipelines.py</div><div class="line">    │  settings.py</div><div class="line">    │  __init__.py</div><div class="line">    │</div><div class="line">    └─spiders</div><div class="line">            __init__.py</div></pre></td></tr></table></figure></p>
<p>&gt;</p>
<blockquote>
<p>这些文件主要是：   </p>
<p>scrapy.cfg: 项目配置文件<br>tutorial/: 项目python模块, 代码将从这里导入<br>tutorial/items.py: 项目items文件<br>tutorial/pipelines.py: 项目管道文件<br>tutorial/settings.py: 项目配置文件<br>tutorial/spiders: 放置spider的目录 </p>
</blockquote>
<h5 id="2-3-2-2-定义Item"><a href="#2-3-2-2-定义Item" class="headerlink" title="2.3.2.2 定义Item"></a>2.3.2.2 定义Item</h5><blockquote>
<p>Items是将要装载抓取的数据的容器，它工作方式像python里面的字典，但它提供更多的保护，比如对未定义的字段填充以防止拼写错误。</p>
<p>它通过创建一个scrapy.item.Item类来声明，定义它的属性为scrpy.item.Field对象，就像是一个对象关系映射(ORM).<br>我们通过将需要的item模型化，来控制从dmoz.org获得的站点数据，比如我们要获得站点的名字，url和网站描述，我们定义这三种属性的域。要做到这点，我们编辑在tutorial目录下的items.py文件，我们的Item类将会是这样<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">from scrapy.item import Item, Field </div><div class="line">class DmozItem(Item):</div><div class="line">    title = Field()</div><div class="line">    link = Field()</div><div class="line">    desc = Field()</div></pre></td></tr></table></figure></p>
<p>刚开始看起来可能会有些困惑，但是定义这些item能让你用其他Scrapy组件的时候知道你的 items到底是什么。</p>
</blockquote>
<h5 id="2-3-2-3-我们的第一个爬虫-Spider"><a href="#2-3-2-3-我们的第一个爬虫-Spider" class="headerlink" title="2.3.2.3 我们的第一个爬虫(Spider)"></a>2.3.2.3 我们的第一个爬虫(Spider)</h5><blockquote>
<p>Spider是用户编写的类，用于从一个域（或域组）中抓取信息。   </p>
<p>他们定义了用于下载的URL的初步列表，如何跟踪链接，以及如何来解析这些网页的内容用于提取items。 </p>
<p>要建立一个Spider，你必须为scrapy.spider.BaseSpider创建一个子类，并确定三个主要的、强制的属性：    </p>
<p>name：爬虫的识别名，它必须是唯一的，在不同的爬虫中你必须定义不同的名字.<br>start_urls：爬虫开始爬的一个URL列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些URLS开始。其他子URL将会从这些起始URL中继承性生成。<br>parse()：爬虫的方法，调用时候传入从每一个URL传回的Response对象作为参数，response将会是parse方法的唯一的一个参数,<br>这个方法负责解析返回的数据、匹配抓取的数据(解析为item)并跟踪更多的URL。    </p>
<p>这是我们的第一只爬虫的代码，将其命名为dmoz_spider.py并保存在tutorial\spiders目录下。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">from scrapy.spider import BaseSpider</div><div class="line"></div><div class="line">class DmozSpider(BaseSpider):</div><div class="line">    name = &quot;dmoz&quot;</div><div class="line">    allowed_domains = [&quot;dmoz.org&quot;]</div><div class="line">    start_urls = [</div><div class="line">        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;,</div><div class="line">        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;</div><div class="line">    ]</div><div class="line"></div><div class="line">    def parse(self, response):</div><div class="line">        filename = response.url.split(&quot;/&quot;)[-2]</div><div class="line">        open(filename, &apos;wb&apos;).write(response.body)</div></pre></td></tr></table></figure>
<h5 id="2-3-2-3-运行"><a href="#2-3-2-3-运行" class="headerlink" title="2.3.2.3 运行"></a>2.3.2.3 运行</h5><p>为了让我们的爬虫工作，我们返回项目主目录执行以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">T:\tutorial&gt;scrapy crawl dmoz</div></pre></td></tr></table></figure></p>
<blockquote>
<p>scrapy crawl dmoz 命令从dmoz.org域启动爬虫。 你将会获得如下类似输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">T:\tutorial&gt;scrapy crawl dmoz</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] INFO: Scrapy 0.14.4 started (bot: tutorial)</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] DEBUG: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] DEBUG: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, RedirectMiddleware, CookiesMiddleware, HttpCompressionMiddleware, ChunkedTransferMiddleware, DownloaderStats</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] DEBUG: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] DEBUG: Enabled item pipelines:</div><div class="line">2012-07-13 19:14:45+0800 [dmoz] INFO: Spider opened</div><div class="line">2012-07-13 19:14:45+0800 [dmoz] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] DEBUG: Telnet console listening on 0.0.0.0:6023</div><div class="line">2012-07-13 19:14:45+0800 [scrapy] DEBUG: Web service listening on 0.0.0.0:6080</div><div class="line">2012-07-13 19:14:46+0800 [dmoz] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&gt; (referer: None)</div><div class="line">2012-07-13 19:14:46+0800 [dmoz] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt; (referer: None)</div><div class="line">2012-07-13 19:14:46+0800 [dmoz] INFO: Closing spider (finished)</div><div class="line">2012-07-13 19:14:46+0800 [dmoz] INFO: Dumping spider stats:</div><div class="line">        &#123;&apos;downloader/request_bytes&apos;: 486,</div><div class="line">         &apos;downloader/request_count&apos;: 2,</div><div class="line">         &apos;downloader/request_method_count/GET&apos;: 2,</div><div class="line">         &apos;downloader/response_bytes&apos;: 13063,</div><div class="line">         &apos;downloader/response_count&apos;: 2,</div><div class="line">         &apos;downloader/response_status_count/200&apos;: 2,</div><div class="line">         &apos;finish_reason&apos;: &apos;finished&apos;,</div><div class="line">         &apos;finish_time&apos;: datetime.datetime(2012, 7, 13, 11, 14, 46, 703000),</div><div class="line">         &apos;scheduler/memory_enqueued&apos;: 2,</div><div class="line">         &apos;start_time&apos;: datetime.datetime(2012, 7, 13, 11, 14, 45, 500000)&#125;</div><div class="line">2012-07-13 19:14:46+0800 [dmoz] INFO: Spider closed (finished)</div><div class="line">2012-07-13 19:14:46+0800 [scrapy] INFO: Dumping global stats:</div><div class="line">        &#123;&#125;</div></pre></td></tr></table></figure></p>
<p>注意包含 [dmoz]的行 ，那对应着我们的爬虫。你可以看到start_urls中定义的每个URL都有日志行。因为这些URL是起始页面，所以他们没有引用(referrers)，所以在每行的末尾你会看到 (referer: <none>).<br>有趣的是，在我们的 parse  方法的作用下，两个文件被创建：分别是 Books 和 Resources，这两个文件中有URL的页面内容。 </none></p>
</blockquote>
<hr>
<h5 id="2-3-2-4-scrapy结束"><a href="#2-3-2-4-scrapy结束" class="headerlink" title="2.3.2.4 scrapy结束"></a>2.3.2.4 scrapy结束</h5><p>至此,scrapy的爬虫算结束了.</p>
<h3 id="2-4-redis"><a href="#2-4-redis" class="headerlink" title="2.4 redis"></a>2.4 redis</h3><p>Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。</p>
<h4 id="2-4-1-redis的下载安装："><a href="#2-4-1-redis的下载安装：" class="headerlink" title="2.4.1 redis的下载安装："></a>2.4.1 redis的下载安装：</h4><p><strong>此步骤安装在CentOS6.5上</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ wget http://download.redis.io/releases/redis-3.2.6.tar.gz</div><div class="line">$ tar xzf redis-3.2.6.tar.gz</div><div class="line">$ cd redis-3.2.6</div><div class="line">$ make</div></pre></td></tr></table></figure></p>
<h4 id="2-4-2-redis的运行："><a href="#2-4-2-redis的运行：" class="headerlink" title="2.4.2 redis的运行："></a>2.4.2 redis的运行：</h4><h5 id="server"><a href="#server" class="headerlink" title="server:"></a>server:</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">src/redis-server ./redis.conf</div></pre></td></tr></table></figure>
<h5 id="client"><a href="#client" class="headerlink" title="client:"></a>client:</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#连接上client后,可以通过get set 的方法测试</div><div class="line">[l@bogon redis-3.2.6]$ src/redis-cli -h 192.168.230.131</div><div class="line">192.168.230.131:6379&gt; set &apos;hello&apos; &apos;world&apos;</div><div class="line">OK</div><div class="line">192.168.230.131:6379&gt; get &apos;hello&apos;</div><div class="line">&quot;world&quot;</div><div class="line">192.168.230.131:6379&gt;</div></pre></td></tr></table></figure>
<h3 id="2-5-Elasticsearch"><a href="#2-5-Elasticsearch" class="headerlink" title="2.5 Elasticsearch"></a>2.5 Elasticsearch</h3><h4 id="2-5-1-Elasticsearch下载安装"><a href="#2-5-1-Elasticsearch下载安装" class="headerlink" title="2.5.1 Elasticsearch下载安装"></a>2.5.1 Elasticsearch下载安装</h4><p>Elasticsearch的下载安装,建议查看过往的教程.<a href="http://" target="_blank" rel="external">教程</a>.</p>
<h3 id="2-6-教程结尾"><a href="#2-6-教程结尾" class="headerlink" title="2.6 教程结尾"></a>2.6 教程结尾</h3><p>python-scrapy-redis-elasticsearch的部署实践教程到这里已经结束.后面将会提供实际的例子来展示这技术栈如何爬取网站.</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
            <a href="/tags/scrapy/" rel="tag"># scrapy</a>
          
            <a href="/tags/redis/" rel="tag"># redis</a>
          
            <a href="/tags/elasticsearch/" rel="tag"># elasticsearch</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/01/16/第二篇测试/" rel="next" title="第二篇测试">
                <i class="fa fa-chevron-left"></i> 第二篇测试
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/02/04/架构之路-0-SSM框架搭建/" rel="prev" title="架构之路(0)-SSM框架搭建">
                架构之路(0)-SSM框架搭建 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Cry Rain" />
          <p class="site-author-name" itemprop="name">Cry Rain</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/xinuo" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#py-scrapy-redis-elasticsearch的部署实践"><span class="nav-number">1.</span> <span class="nav-text">py-scrapy-redis-elasticsearch的部署实践</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-前言："><span class="nav-number">1.1.</span> <span class="nav-text">1. 前言：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-作用"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1 作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-系统环境"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2 系统环境</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-下载安装步骤"><span class="nav-number">1.2.</span> <span class="nav-text">2. 下载安装步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Python"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 Python</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-Python下载"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">2.1.1 Python下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-Python安装"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">2.1.2 Python安装</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-pycharm"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 pycharm</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-pycharm下载"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">2.2.1 pycharm下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-pycharm安装"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">2.2.2 pycharm安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-新建一个python项目"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">2.2.3 新建一个python项目</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-scrapy"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.3 scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-0-pip的配置"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">2.3.0 pip的配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-1-scrapy下载安装"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">2.3.1 scrapy下载安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-2-Scrapy-tutorial"><span class="nav-number">1.2.3.3.</span> <span class="nav-text">2.3.2 Scrapy tutorial</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-2-1-目录结构"><span class="nav-number">1.2.3.3.1.</span> <span class="nav-text">2.3.2.1 目录结构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-2-2-定义Item"><span class="nav-number">1.2.3.3.2.</span> <span class="nav-text">2.3.2.2 定义Item</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-2-3-我们的第一个爬虫-Spider"><span class="nav-number">1.2.3.3.3.</span> <span class="nav-text">2.3.2.3 我们的第一个爬虫(Spider)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-2-3-运行"><span class="nav-number">1.2.3.3.4.</span> <span class="nav-text">2.3.2.3 运行</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-2-4-scrapy结束"><span class="nav-number">1.2.3.3.5.</span> <span class="nav-text">2.3.2.4 scrapy结束</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-redis"><span class="nav-number">1.2.4.</span> <span class="nav-text">2.4 redis</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-1-redis的下载安装："><span class="nav-number">1.2.4.1.</span> <span class="nav-text">2.4.1 redis的下载安装：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-2-redis的运行："><span class="nav-number">1.2.4.2.</span> <span class="nav-text">2.4.2 redis的运行：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#server"><span class="nav-number">1.2.4.2.1.</span> <span class="nav-text">server:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#client"><span class="nav-number">1.2.4.2.2.</span> <span class="nav-text">client:</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-Elasticsearch"><span class="nav-number">1.2.5.</span> <span class="nav-text">2.5 Elasticsearch</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-1-Elasticsearch下载安装"><span class="nav-number">1.2.5.1.</span> <span class="nav-text">2.5.1 Elasticsearch下载安装</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-教程结尾"><span class="nav-number">1.2.6.</span> <span class="nav-text">2.6 教程结尾</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cry Rain</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  




  
  

  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
